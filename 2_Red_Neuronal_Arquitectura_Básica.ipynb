{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Oa0oy4v4uZ1M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "#!pip install tensorflow-transform\n",
        "#import tensorflow_transform as tft"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelamiento"
      ],
      "metadata": {
        "id": "uA2AsLV-wdJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train - test split"
      ],
      "metadata": {
        "id": "efIvupZlwf0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2)\n",
        "\n",
        "# Normalización de los datos de entrada\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train.reshape(-1, 1))\n",
        "x_test = scaler.transform(x_test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "gkMR4jRvz-sg"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elementos del Modelo"
      ],
      "metadata": {
        "id": "lyatP2sVwiV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas:\n",
        "METRICS = [\n",
        "    keras.metrics.TruePositives(name='tp'),  # Verdaderos positivos\n",
        "    keras.metrics.FalsePositives(name='fp'),  # Falsos positivos\n",
        "    keras.metrics.TrueNegatives(name='tn'),  # Verdaderos negativos\n",
        "    keras.metrics.FalseNegatives(name='fn'),  # Falsos negativos\n",
        "    keras.metrics.BinaryAccuracy(name='accuracy'),  # Precisión binaria\n",
        "    keras.metrics.Precision(name='precision'),  # Precisión\n",
        "    keras.metrics.Recall(name='recall'),  # Sensibilidad\n",
        "    keras.metrics.AUC(name='auc'),  # Área bajo la curva ROC\n",
        "]\n",
        "\n",
        "# Modelo: Entradas, Métricas\n",
        "def make_model(inputs=['xs', 'ys'], metrics=METRICS):\n",
        "    input_shape = x_train.shape[1]\n",
        "\n",
        "    # Cuerpo del modelo\n",
        "\n",
        "    ## Objeto Sequential.\n",
        "    model = Sequential()\n",
        "\n",
        "    ## Capa de entrada: Dimensión de entrada que se ajusta a las columnas de x_train.\n",
        "    ## Función de activación: \"relu\" como regla general.\n",
        "    model.add(Dense(16, activation='relu', input_shape=(input_shape,)))\n",
        "\n",
        "    ## Nuevas capas:\n",
        "    ## Agregarlas hasta el modelo se sobreajuste.\n",
        "    ## Intentaremos luego combatir el sobreajuste con la regularización.\n",
        "    model.add(Dense(5, activation='relu', input_shape=(16,)))\n",
        "\n",
        "    ## Capa de salida\n",
        "    ## La forma de entrada/salida de la capa debe coincidir entre las capas\n",
        "    model.add(Dense(16, activation='relu', input_shape=(5,)))\n",
        "\n",
        "    ## Regularización\n",
        "    ## Las dropout corresponde a una técnica de regularización para prevenir el sobreajuste en modelos de redes neuronales.\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    # Los valores de salida deben tener la misma dimensión que la función de activación.\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compilación\n",
        "    # Optimización: Adam (regresión, clasificación) o  mean square (regresión) o gradient (clasificación)\n",
        "    # Función de pérdida: sparse_cross_entropy\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(optimizer=optimizer, loss='sparse_cross_entropy', metrics=metrics)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "i6fpGP5G1mMt"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresión"
      ],
      "metadata": {
        "id": "WgMrT9i0xQUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Definición del modelo\n",
        "model = keras.Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(1,)),  # Capa oculta adicional con 64 unidades y función de activación ReLU\n",
        "    Dense(32, activation='relu'),                    # Otra capa oculta con 32 unidades y función de activación ReLU\n",
        "    Dense(1)                                         # Capa de salida con activación lineal (regresión)\n",
        "])\n",
        "\n",
        "#Compilación del modelo antes de entrenarlo\n",
        "model.compile(loss='mean_squared_error',  # Función de pérdida para regresión\n",
        "              optimizer='adam', # algoritmo de optimización Adam para entrenar tu red neuronal\n",
        "              metrics=['mae', 'mse'])  # Métricas para evaluar el modelo\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=1)\n",
        "\n",
        "# Evaluación del modelo en el conjunto de prueba\n",
        "loss, mae, mse = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Predicción con el modelo entrenado\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcc7uDc2xQwS",
        "outputId": "db5fec60-ad45-4787-8cdd-81f570e1f742"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 15.7195 - mae: 3.0575 - mse: 15.7195\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 15.3221 - mae: 3.0202 - mse: 15.3221\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 14.8613 - mae: 2.9810 - mse: 14.8613\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 14.6713 - mae: 2.9613 - mse: 14.6713\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 14.2890 - mae: 2.9282 - mse: 14.2890\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 14.1023 - mae: 2.9075 - mse: 14.1023\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 13.7013 - mae: 2.8748 - mse: 13.7013\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 13.3810 - mae: 2.8442 - mse: 13.3810\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 13.1276 - mae: 2.8200 - mse: 13.1276\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.9515 - mae: 2.8010 - mse: 12.9515\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.5430 - mae: 2.7648 - mse: 12.5430\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.4212 - mae: 2.7457 - mse: 12.4212\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.0596 - mae: 2.7121 - mse: 12.0596\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 11.6956 - mae: 2.6763 - mse: 11.6956\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 11.5032 - mae: 2.6554 - mse: 11.5032\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 11.1948 - mae: 2.6201 - mse: 11.1948\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 10.9532 - mae: 2.5910 - mse: 10.9532\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 10.5803 - mae: 2.5504 - mse: 10.5803\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 10.2829 - mae: 2.5180 - mse: 10.2829\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 10.0548 - mae: 2.4853 - mse: 10.0548\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5142 - mae: 2.4300 - mse: 9.5142\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.1676 - mae: 2.3897 - mse: 9.1676\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.7976 - mae: 2.3430 - mse: 8.7976\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.4983 - mae: 2.3037 - mse: 8.4983\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.2311 - mae: 2.2624 - mse: 8.2311\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.6838 - mae: 2.1987 - mse: 7.6838\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.2482 - mae: 2.1399 - mse: 7.2482\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.7264 - mae: 2.0676 - mse: 6.7264\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.4517 - mae: 2.0181 - mse: 6.4517\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.8398 - mae: 1.9344 - mse: 5.8398\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.5641 - mae: 1.8820 - mse: 5.5641\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.0397 - mae: 1.8054 - mse: 5.0397\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.5984 - mae: 1.7307 - mse: 4.5984\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.0354 - mae: 1.6358 - mse: 4.0354\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.7074 - mae: 1.5671 - mse: 3.7074\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.4445 - mae: 1.5047 - mse: 3.4445\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.9626 - mae: 1.4101 - mse: 2.9626\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.6560 - mae: 1.3361 - mse: 2.6560\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.2617 - mae: 1.2409 - mse: 2.2617\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8372 - mae: 1.1391 - mse: 1.8372\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6315 - mae: 1.0672 - mse: 1.6315\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3243 - mae: 0.9813 - mse: 1.3243\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0656 - mae: 0.8948 - mse: 1.0656\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8959 - mae: 0.8226 - mse: 0.8959\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6605 - mae: 0.7248 - mse: 0.6605\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5758 - mae: 0.6681 - mse: 0.5758\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4463 - mae: 0.5991 - mse: 0.4463\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2937 - mae: 0.5070 - mse: 0.2937\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4492 - mse: 0.2277\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1869 - mae: 0.4073 - mse: 0.1869\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1339 - mae: 0.3523 - mse: 0.1339\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0944 - mae: 0.3015 - mse: 0.0944\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0603 - mae: 0.2450 - mse: 0.0603\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0487 - mae: 0.2189 - mse: 0.0487\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0361 - mae: 0.1863 - mse: 0.0361\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1593 - mse: 0.0289\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 0.1334 - mse: 0.0237\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.1202 - mse: 0.0201    \n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.1145 - mse: 0.0181    \n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.1158 - mse: 0.0175\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.1107 - mse: 0.0154\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.1085 - mse: 0.0145\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.1044 - mse: 0.0134\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.1018 - mse: 0.0127\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0989 - mse: 0.0121\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0961 - mse: 0.0114\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0919 - mse: 0.0105\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0885 - mse: 0.0097\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0846 - mse: 0.0090\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0811 - mse: 0.0083\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0782 - mse: 0.0078\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0769 - mse: 0.0075\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0067 - mae: 0.0732 - mse: 0.0067\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0063 - mae: 0.0707 - mse: 0.0063\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0677 - mse: 0.0057\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0651 - mse: 0.0053\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0629 - mse: 0.0050\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0600 - mse: 0.0046\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0573 - mse: 0.0042\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0545 - mse: 0.0038    \n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0523 - mse: 0.0035\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0500 - mse: 0.0032    \n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0501 - mse: 0.0032\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0475 - mse: 0.0028    \n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0461 - mse: 0.0026\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0024 - mae: 0.0447 - mse: 0.0024\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0412 - mse: 0.0021    \n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0393 - mse: 0.0020\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0374 - mse: 0.0018\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0359 - mse: 0.0016    \n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0346 - mse: 0.0015    \n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0339 - mse: 0.0014\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0321 - mse: 0.0012\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0304 - mse: 0.0011    \n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0289 - mse: 0.0010    \n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.1769e-04 - mae: 0.0274 - mse: 9.1769e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.5979e-04 - mae: 0.0268 - mse: 8.5979e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.6084e-04 - mae: 0.0255 - mse: 7.6084e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.7960e-04 - mae: 0.0242 - mse: 6.7960e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.0040e-04 - mae: 0.0226 - mse: 6.0040e-04\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.8045 - mae: 0.6383 - mse: 0.8045\n",
            "1/1 [==============================] - 0s 81ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación"
      ],
      "metadata": {
        "id": "m16V2bCOxTv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición del modelo\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(1,)),  # Capa oculta adicional con 64 neuronas y función de activación ReLU\n",
        "    Dense(32, activation='relu'),                    # Otra capa oculta con 32 neuronas y función de activación ReLU\n",
        "    Dense(1, activation='sigmoid')                    # Capa de salida con función de activación sigmoide (clasificación binaria)\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',  # Función de pérdida para clasificación binaria\n",
        "              optimizer='adam',              # Algoritmo de optimización Adam\n",
        "              metrics=['accuracy'])           # Métricas para evaluar el modelo\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=1)\n",
        "\n",
        "# Evaluación del modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Predicción con el modelo entrenado\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Redondeamos las predicciones a 0 o 1 para clasificación binaria\n",
        "rounded_predictions = np.round(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-a0AEpDxV0p",
        "outputId": "eff0e744-cc10-4f72-c65c-30d390a75fd8"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 0.8275 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2544 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -0.1005 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -0.1981 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -0.3067 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -0.4292 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -0.5449 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -0.6952 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -0.8751 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -1.0056 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -1.1657 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -1.3033 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -1.5155 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -1.7355 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -1.9443 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -2.1239 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -2.3648 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -2.5720 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -2.9209 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -3.1314 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -3.4231 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: -3.6591 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -4.0593 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -4.2062 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -4.7247 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -4.9299 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -5.2575 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -5.8027 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -6.0642 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -6.7120 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -7.0453 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -7.5192 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -8.1207 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -8.3165 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -9.2024 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -9.7522 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -10.1351 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 6ms/step - loss: -10.9151 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -11.6457 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -11.9677 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -12.7858 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -13.5936 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -14.4131 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -15.4490 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -16.3903 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -17.2536 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -18.2470 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -19.1757 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -20.4030 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -21.3993 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -22.1756 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -23.6455 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -24.5643 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -26.4039 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -27.3970 - accuracy: 0.2500\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -28.8314 - accuracy: 0.2500\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -30.0650 - accuracy: 0.2500\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -31.4132 - accuracy: 0.2500 \n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -33.4751 - accuracy: 0.2500\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -35.3180 - accuracy: 0.2500\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -36.8438 - accuracy: 0.2500\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -38.0167 - accuracy: 0.2500\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -39.8387 - accuracy: 0.2500\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -42.3703 - accuracy: 0.2500\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -43.1335 - accuracy: 0.2500 \n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -45.9360 - accuracy: 0.2500\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -47.9191 - accuracy: 0.2500\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -50.0943 - accuracy: 0.2500\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: -51.6707 - accuracy: 0.2500\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -54.7710 - accuracy: 0.2500\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -56.9440 - accuracy: 0.2500\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -59.3016 - accuracy: 0.2500\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -60.7627 - accuracy: 0.2500\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -62.9610 - accuracy: 0.2500 \n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -65.9864 - accuracy: 0.2500 \n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -69.4589 - accuracy: 0.2500\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -72.0263 - accuracy: 0.2500\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -74.7936 - accuracy: 0.2500\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -77.5807 - accuracy: 0.2500\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -80.5149 - accuracy: 0.2500\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -84.1295 - accuracy: 0.2500\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -86.4391 - accuracy: 0.2500\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -89.2104 - accuracy: 0.2500\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -92.0204 - accuracy: 0.2500 \n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -97.3638 - accuracy: 0.2500\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -99.3069 - accuracy: 0.2500\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -103.1498 - accuracy: 0.2500\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -106.7929 - accuracy: 0.2500\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -110.1960 - accuracy: 0.2500\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -113.5808 - accuracy: 0.2500\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -117.5466 - accuracy: 0.2500\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -121.8889 - accuracy: 0.2500\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -126.9144 - accuracy: 0.2500\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: -130.7677 - accuracy: 0.2500\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: -133.5804 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -156.4435 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "\n",
        "La principal diferencia entre los dos fragmentos de código radica en el propósito de los modelos y en la configuración correspondiente utilizada durante la definición, compilación y evaluación del modelo.\n",
        "\n",
        "Código 1:\n",
        "\n",
        "Propósito del modelo: Regresión\n",
        "Arquitectura del modelo: \n",
        "\n",
        "El modelo consta de tres capas densas. \n",
        "La primera capa tiene 64 unidades y utiliza la función de activación ReLU. \n",
        "La segunda capa tiene 32 unidades y también utiliza la función de activación ReLU. \n",
        "La última capa es la capa de salida y no se especifica ninguna función de activación, lo que implica que se utiliza una activación lineal.\n",
        "\n",
        "Código 2:\n",
        "\n",
        "Propósito del modelo: Clasificación binaria\n",
        "Arquitectura del modelo: \n",
        "\n",
        "El modelo también consta de tres capas densas. \n",
        "La primera capa tiene 64 unidades y utiliza la función de activación ReLU. \n",
        "La segunda capa tiene 32 unidades y también utiliza la función de activación ReLU. \n",
        "La última capa es la capa de salida con la función de activación sigmoide, lo que indica que se trata de un problema de clasificación binaria.\n",
        "\n",
        "Como capa de salida utiliza una función de activación sigmoide, las predicciones serán probabilidades. Cada valor de predicción será un número en el rango de 0 a 1, que representa la probabilidad estimada de que el ejemplo pertenezca a la clase positiva.\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "K8uPDmY0-34d"
      }
    }
  ]
}